{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd /Users/akshitasingh/Downloads/273A_ML/1_MLProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23fbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# other stats/math imports\n",
    "import math\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes = pd.read_csv(\"/Users/akshitasingh/Downloads/273A_ML/1_MLProject/dataset_diabetes/diabetic_data.csv\", delimiter=None) \n",
    "diabetes = pd.read_csv(\"diabetic_data.csv\", delimiter=None) \n",
    "diabetes = pd.DataFrame(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e199d",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### Numerical Features \n",
    "In this dataset the feature names make numerical value features self-evident. Each column with numerical features starts with \"num_...\"\n",
    "### Categorical Features\n",
    "Essentially every feature that is numerical can be considered categorical but it is not as simple as that. \n",
    "1) 2 features are patient ID features: ['encounter_id', 'patient_nbr']. It does not make sense to include them (unless we are considering a personalized Machine Learning model) <br>\n",
    "2) It also does not make sense to include the target feature which is also categorical: ['readmitted'] <br>\n",
    "3) Certain features have numerical values that represent categories, such as: ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']. This is something we will investigate further. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list column names of features that consist of numeric values\n",
    "# (in this dataset the feature names make numerical value features self-evident)\n",
    "feat_num = ['num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "       'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']\n",
    "\n",
    "# numerics = ['int16','int32','int64','float16','float32','float64']\n",
    "# feat_num = list(diabetes.select_dtypes(include=numerics).columns)\n",
    "\n",
    "# list column names of features that consist of categorical values\n",
    "feat_cat = ['race', 'gender', 'age', 'weight',\n",
    "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'time_in_hospital', 'payer_code', 'medical_specialty', 'diag_1',\n",
    "       'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "       'metformin-pioglitazone', 'change', 'diabetesMed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c4470",
   "metadata": {},
   "source": [
    "#### Count distinct values for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0441d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count = defaultdict(int)\n",
    "for f in feat_cat:\n",
    "    cat_count[f] = len(diabetes[f].value_counts())\n",
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features \"examide\" and \"citoglipton\" have only one value through so they can be dropped from consideration\n",
    "diabetes = diabetes.drop(['examide', 'citoglipton'], axis = 1)\n",
    "feat_cat = [f for f in feat_cat if f not in ('examide', 'citoglipton')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all medication features after removing  \"examide\" and \"citoglipton\"\n",
    "medications = list(diabetes.columns)[24:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c2327f",
   "metadata": {},
   "source": [
    "## Categorical features - Investigating Categories\n",
    "We picked some features we thought would be relevant to look into further <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b1676",
   "metadata": {},
   "source": [
    "### Discharge Disposition ID: \n",
    "From the ID mapping that UCI ML Repository shared with us, some categories here relate to death or terminally ill facilities. Any patient that falls into these categories should possibly not be considered in our predictions because there is no way they can be readmitted. If we were to consider them, we would possibly be biasing our predictions towards \"NO\" readmission, which would be incorrect. Nonetheless, we might want to consider some patients who had multiple re-admissions and hence we will not completely eliminate all patients that fall in the death/hospice categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop rows where discharge_disposition_id indicates death or hospice\n",
    "# diabetes = diabetes.drop(diabetes[diabetes.discharge_disposition_id.isin([11,13,14,19,20,21])].index)\n",
    "## OR, Create a Boolean for patients that died/went to hospice vs that didn't\n",
    "diabetes['disposition_boolean'] = np.where((diabetes['discharge_disposition_id'].isin([11,13,14,19,20,21])),1,0)\n",
    "diabetes['discharge_disposition_id'].value_counts()\n",
    "feat_cat.append('disposition_boolean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463725dd",
   "metadata": {},
   "source": [
    "### Diagnosis Features - diag_1, diag_2, diag_3: \n",
    "- Each of the 3 features containts 700+ categories of type string <br> \n",
    "- Some of these categories are essentially numbers (floats) while others are hard strings <br>\n",
    "- We convert all the strings that can be converted into floats, and coerce the others into 'nan' <br>\n",
    "- Any unknowns (?) and non-float diagnisis (ex. V50) are then categorized as \"Other\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e30268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_cat(diag_feat):\n",
    "    diabetes[diag_feat] = pd.to_numeric(diabetes[diag_feat],errors= 'coerce')\n",
    "    diabetes[diag_feat] = diabetes[diag_feat].fillna(0)\n",
    "    \n",
    "    for ind in range(len(diabetes)):\n",
    "        if diabetes[diag_feat][ind] == 'nan':\n",
    "            diabetes[diag_feat][ind] = \"Other\"\n",
    "        elif round(diabetes[diag_feat][ind]) in [250,251]:\n",
    "            diabetes[diag_feat][ind] = \"Diabetes\"\n",
    "        elif diabetes[diag_feat][ind] in range(390,460) or diabetes[diag_feat][ind] == 785:\n",
    "            diabetes[diag_feat][ind] = \"Circulatory\"\n",
    "        elif diabetes[diag_feat][ind] in range(460,520) or diabetes[diag_feat][ind] == 786:\n",
    "            diabetes[diag_feat][ind] = \"Respiratory\"\n",
    "        elif diabetes[diag_feat][ind] in range(520,580) or diabetes[diag_feat][ind] == 787:\n",
    "            diabetes[diag_feat][ind] = \"Digestive\"\n",
    "        elif diabetes[diag_feat][ind] in range(800,1000):\n",
    "            diabetes[diag_feat][ind] = \"Injury\"\n",
    "        elif diabetes[diag_feat][ind] in range(710,740):\n",
    "            diabetes[diag_feat][ind] = \"Musculoskeletel\"\n",
    "        else:\n",
    "            diabetes[diag_feat][ind] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49480a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_feat = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "for f in diag_feat:\n",
    "    diag_cat(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes['diag_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055745fa",
   "metadata": {},
   "source": [
    "### Gender, Age, Admissions Type, and Admissions Source\n",
    "Age is a categorical feature, which we can consider turning into a numerical value by finding the mean of each range. This converts the feature into a numeric (but we shall not consider this as part of PCA because we understand that Age is an important factor in understanding readmissions and hence should not be put under the dimensionality reduction bucket. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76024932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "diabetes = diabetes[diabetes['gender'] != 'Unknown/Invalid']\n",
    "diabetes['gender'].value_counts()\n",
    "\n",
    "# Age\n",
    "age_dict = {'[0-10)' : 5,\n",
    "'[10-20)' : 15,\n",
    "'[20-30)' : 25, \n",
    "'[30-40)' : 35, \n",
    "'[40-50)' : 45, \n",
    "'[50-60)' : 55,\n",
    "'[60-70)' : 65, \n",
    "'[70-80)' : 75,\n",
    "'[80-90)' : 85,\n",
    "'[90-100)' : 95}\n",
    "\n",
    "diabetes['age'] = diabetes['age'].apply(lambda x : age_dict[x])\n",
    "\n",
    "# Admissions\n",
    "diabetes['admission_type_id'] = \\\n",
    "diabetes['admission_type_id'].apply(lambda x : 'Unavailable' if int(x) in [5, 6, 8]\n",
    "                                                            else 'Elective')\n",
    "\n",
    "\n",
    "\n",
    "diabetes['admission_source_id'] = \\\n",
    "diabetes['admission_source_id'].apply(lambda x : 'Referral' if int(x) in [5, 6, 8]\n",
    "                                            else ('Emergency Room' if int(x) in [7]\n",
    "                                            else 'Other'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e27af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f79c1f91",
   "metadata": {},
   "source": [
    "## Investigating Multiple Readmissions\n",
    "Some patients show up more than once in our dataset. It is a very small subset of the larger dataset so we first start with considering only once patient visit - which, in our case, would be the very last occurance for that patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7422c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of multiple readmissions for a single patient\n",
    "# data = diabetes[diabetes['readmitted'] != 'NO']\n",
    "# unique_patients = data[['patient_nbr']]\n",
    "# unique_patients = unique_patients['patient_nbr'].value_counts().to_frame()\n",
    "# unique_patients[\"index\"] = unique_patients.index\n",
    "# len(unique_patients[unique_patients[\"patient_nbr\"] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = diabetes.drop_duplicates(subset= 'patient_nbr', keep='last')\n",
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f39f2",
   "metadata": {},
   "source": [
    "## Investigating Missing Values (?) \n",
    "Features with missing values: <br>\n",
    "**Weight** - replaced it with the mode <br>\n",
    "Another way to impute the missing weights would have been to find the closest neighbors. For us, a \"neighbor\" would be another patient with similar comorbidities. These comorbidities could be respresented in multiple ways such as (1) diagonasis (dia_1, 2, and 3) 2) number of meds, <br>\n",
    "**Race** - replaced it with \"UNK\" <br>\n",
    "**Medical Speciality** - replaced it with \"UNK\" <br>\n",
    "**Payer Code** - replaced it with \"UNK\" <br>\n",
    "\n",
    "(**diag_1, diag_2, diag_3** also had missing values but those have already been handled above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2343cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diabetes.columns:\n",
    "    if diabetes[col].dtype == object:\n",
    "        count = diabetes[col][diabetes[col] == '?'].count()\n",
    "        if count > 0:\n",
    "            print(col, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e2f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weights: Because most weights are missing, we replace the ? with most common weight\n",
    "diabetes['weight'] = np.where((diabetes['weight'] == \"?\"),\"[75-100)\",diabetes['weight'])\n",
    "## Race: replace with UNK\n",
    "diabetes['race'] = np.where((diabetes['race'] == \"?\"),\"UNK\",diabetes['race'])\n",
    "## Medical Speciality: replace with UNK\n",
    "diabetes['medical_specialty'] = np.where((diabetes['medical_specialty'] == \"?\"),\"UNK\",diabetes['medical_specialty'])\n",
    "## payer_code: replace with UNK\n",
    "diabetes['payer_code'] = np.where((diabetes['race'] == \"?\"),\"UNK\",diabetes['payer_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebced3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop payer_code because it doesn't seem to explain very much \n",
    "# drop medical speciality because it has too many missing values\n",
    "feat_cat = [f for f in feat_cat if f not in ('payer_code', 'medical speciality')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0817d1",
   "metadata": {},
   "source": [
    "### Data after Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b25a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes[feat_num + feat_cat]\n",
    "y = diabetes['readmitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e33e",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, Ytr, Yte = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0993a94",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f7850",
   "metadata": {},
   "source": [
    "## Feature Scaling - should we scale before train_test_split???\n",
    "As a first step, we will only normalize the numerical features. Later on, we will consider normalizing all features (for instance, if we use a multivariate feature selection model such as Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numerical features from strings to floats\n",
    "for f in feat_num:\n",
    "    diabetes[f] = pd.to_numeric(diabetes[f],errors= 'coerce')\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling training data\n",
    "Xtr_num = Xtr[feat_num]\n",
    "scaler.fit(Xtr_num)\n",
    "Xtr_numSc = scaler.fit_transform(Xtr_num)\n",
    "\n",
    "# transforming test data based on the fit from training data\n",
    "Xte_num = Xte[feat_num]\n",
    "Xte_numSc = scaler.transform(Xte_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the new training data with scaled features\n",
    "Xtr_cat = np.array(Xtr[feat_cat])\n",
    "Xtr = np.concatenate([Xtr_numSc, Xtr_cat], axis = 1)\n",
    "Xtr = pd.DataFrame(Xtr)\n",
    "Xtr.columns = [feat_num + feat_cat]\n",
    "\n",
    "# construct the new test data with the scaled features\n",
    "Xte_cat = np.array(Xte[feat_cat])\n",
    "Xte = np.concatenate([Xte_numSc, Xte_cat], axis = 1)\n",
    "Xte = pd.DataFrame(Xte)\n",
    "Xte.columns = [feat_num + feat_cat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777eac74",
   "metadata": {},
   "source": [
    "## Feature Selection - Numerical Features  (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e015a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(Xtr_numSc)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 8, step=1)\n",
    "Var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, Var, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 11, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.90, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '90% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compoonents that explain 90% of the variances \n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "# fit PCA on the training data\n",
    "XtrPCA_num = pca.fit_transform(Xtr_numSc)\n",
    "XtrPCA_num = pd.DataFrame(XtrPCA_num)\n",
    "XtrPCA_num.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n",
    "# XtrPCA_num\n",
    "\n",
    "# transform test data based on the PCA fit from training\n",
    "XtePCA_num = pca.transform(Xte_numSc)\n",
    "XtePCA_num = pd.DataFrame(XtePCA_num)\n",
    "XtePCA_num.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n",
    "# XtePCA_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d947c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5b7c32f",
   "metadata": {},
   "source": [
    "## Feature Selection - Categorical Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474dac14",
   "metadata": {},
   "source": [
    "### Step 1: Investigate the value count for each medication\n",
    "If we realize that hardly anyone was prescribed that medication, it is perhaps a good idea to not consider it in our analysis <br>\n",
    "\n",
    "We run the risk of excluding patients that were specifically chosen for rare medications which hardly prescribed (and hence eliminated from our feature set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70000\n",
    "\n",
    "med_count = defaultdict(list)\n",
    "\n",
    "for med in medications:\n",
    "    # count the number of Nos, Ups, Downs, and Steadys for each medication\n",
    "    med_count[med].append(list(diabetes[med].value_counts()))\n",
    "    \n",
    "    # if the number of Nos is > 100K, disregard the medication for now \n",
    "    if med_count[med][0][0] > threshold:\n",
    "        med_count.pop(med)\n",
    "med_count\n",
    "meds_new = list(med_count)\n",
    "# meds_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f61066",
   "metadata": {},
   "source": [
    "### Step 2: Chi Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af04a4",
   "metadata": {},
   "source": [
    "Lets first try to find any relations between the medication features <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531a642",
   "metadata": {},
   "source": [
    "#### Approach 1: Cross Tabulation\n",
    "$D$ = Number of Medication features <br>\n",
    "Null Hypothesis ($H_O$): Features are independent - there is no relationship between features $x^i$ and $x^j$ where $i, j$ $\\in$ $(1,...,D)$ <br>\n",
    "Alternate Hypothesis ($H_1$): Features are independent - there is a relationship between features <br>\n",
    "Let's consider p-value for $H_O$ = .05 $\\Rightarrow$ if p-value for a relation is < .05, then we fail to reject $H_O$ <br>\n",
    "\n",
    "As we can see, none of our p-values are greater than the significance level, so we fail to reject the null hypothesis for any of them. Thus, we continue to consider all the medication features to be independent from each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18988770",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_p = [[0]*7 for _ in range(7)]\n",
    "for med1 in meds_new:\n",
    "    for med2 in meds_new:\n",
    "        chi_p[meds_new.index(med1)][meds_new.index(med2)] = chi2_contingency(pd.crosstab(diabetes[med1], diabetes[med2]))[1]\n",
    "chi_p = np.array(chi_p)   \n",
    "# chi_p       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f23f43",
   "metadata": {},
   "source": [
    "#### Approach 2: Ordinal / One Hot Encoding\n",
    "come back to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode some catagorical features in the input data\n",
    "# def prepare_inputs(Xtr, Xte):\n",
    "#     ordEnc = OrdinalEncoder()\n",
    "#     ordEnc.fit(Xte)\n",
    "#     XtrEnc = ordEnc.transform(Xtr)\n",
    "#     XteEnc = ordEnc.transform(Xte)\n",
    "#     return XtrEnc, XteEnc\n",
    " \n",
    "# # encode the target feature (categorical)\n",
    "# def prepare_targets(Ytr, Yte):\n",
    "#     labEnc = LabelEncoder()\n",
    "#     labEnc.fit(Ytr)\n",
    "#     YtrEnc = labEnc.transform(Ytr)\n",
    "#     YteEnc = le.transform(Yte)\n",
    "#     return YtrEnc, YteEnc\n",
    " \n",
    "# # feature selection\n",
    "# ## concern - this can only work if we only have categorical features \n",
    "# def select_features(Xtr, Xte, Ytr):\n",
    "#     featSel = SelectKBest(score_func=chi2, k='all')\n",
    "#     featSel.fit(Xtr, Ytr)\n",
    "#     XtrSel = featSel.transform(Xtr)\n",
    "#     XteSel = featSel.transform(Xte)\n",
    "#     return XtrSel, XteSel, featSel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d7bc47",
   "metadata": {},
   "source": [
    "### Final set of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f113c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disposition id replaced by the booleans\n",
    "feat_catN = ['gender', 'age', 'weight', 'admission_type_id', 'admission_source_id', 'disposition_boolean',\n",
    "           'time_in_hospital'] + diag_feat + meds_new + ['change', 'diabetesMed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_cat = Xtr[feat_catN]\n",
    "Xte_cat = Xte[feat_catN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48941fad",
   "metadata": {},
   "source": [
    "## Final Train and Test Data with Selected Catagorical Features and PCAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(XtrPCA_num.columns) + feat_catN\n",
    "\n",
    "# final training data \n",
    "Xtr = np.concatenate([np.array(XtrPCA_num), np.array(Xtr_cat)], axis = 1)\n",
    "Xtr = pd.DataFrame(Xtr)\n",
    "Xtr.columns = features\n",
    "# Xtr\n",
    "\n",
    "# final test data\n",
    "Xte = np.concatenate([np.array(XtePCA_num), np.array(Xte_cat)], axis = 1)\n",
    "Xte = pd.DataFrame(Xte)\n",
    "Xte.columns = features\n",
    "# Xte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a907f61",
   "metadata": {},
   "source": [
    "## One Hot Encode the Final Set of Categorical Features (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25326d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to One Hot Encode\n",
    "feat_OHE = ['gender', 'weight', 'admission_type_id', 'admission_source_id', 'disposition_boolean'] + \\\n",
    "            diag_feat + meds_new + ['change', 'diabetesMed']\n",
    "Xtr_OHE = Xtr[feat_OHE]\n",
    "\n",
    "\n",
    "# fit OHE on to the training data\n",
    "OHE = OneHotEncoder(categories='auto')\n",
    "Xtr_OHE = OHE.fit_transform(Xtr_OHE).toarray()\n",
    "Xtr_OHE = pd.DataFrame(Xtr_OHE)\n",
    "\n",
    "# transform OHE fit into test data\n",
    "Xte_OHE = Xte[feat_OHE]\n",
    "Xte_OHE = OHE.transform(Xte_OHE).toarray()\n",
    "Xte_OHE = pd.DataFrame(Xte_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd964d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract column names for OHE categories\n",
    "OHE_cols = []\n",
    "OHE_cols_ = OHE.categories_\n",
    "for col, vals in zip(Xtr_OHE.columns, OHE_cols_):\n",
    "    for val in vals:\n",
    "        name = str(col) + '_' + str(val)\n",
    "        OHE_cols.append(name)\n",
    "\n",
    "Xtr_OHE.columns = OHE_cols\n",
    "Xte_OHE.columns = OHE_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = pd.concat([XtrPCA_num, Xtr_OHE], axis = 1)\n",
    "Xte = pd.concat([XtePCA_num, Xte_OHE], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153149df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d88ced",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "We try to predict 3 things: <br>\n",
    "1) Readmissions <br>\n",
    "2) Readmissions <30 and >30 days <br>\n",
    "3) Multiple Readmissions <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176d68b",
   "metadata": {},
   "source": [
    "# Problem 1: Predict Readmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ce615",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytr = (Ytr!=\"NO\").astype(int).reset_index(drop = True)\n",
    "Yte = (Yte!=\"NO\").astype(int).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling\n",
    "# smote = SMOTE(random_state=0)\n",
    "# XtrSm, YtrSm = smote.fit_resample(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state=0)\n",
    "XtrSm2, YtrSm2 = cc.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad94934",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression\n",
    "\n",
    "We run 6 different logistic regression models: <br>\n",
    "1) logReg_Bal_L1 <br>\n",
    ">   a) Balanced dataset <br>\n",
    "    b) L1 Regularization (Lasso) <br>\n",
    "\n",
    "2) logReg_Bal_L2 <br>\n",
    ">   a) Balanced dataset <br>\n",
    "    b) L2 Regularization (Ridge) <br>\n",
    "\n",
    "3) logReg_Unbal_L1 <br>\n",
    ">   a) Balanced dataset <br>\n",
    "    b) L1 Regularization (Lasso) <br>\n",
    "\n",
    "4) logReg_Unbal_L2 <br>\n",
    ">   a) Unbalanced dataset <br>\n",
    "    b) L2 Regularization (Ridge) <br>\n",
    "\n",
    "2) logReg_Smote_L1 <br>\n",
    ">   a) Balanced dataset <br>\n",
    "    b) L1 Regularization (Lass) <br>\n",
    "\n",
    "5) logReg_Smote_L2 <br>\n",
    ">   a) Balanced dataset <br>\n",
    "    b) L2 Regularization (Ridge) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a05691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running logistic regression on balanced dataset, while including L1 Regularization (Lasso)\n",
    "\n",
    "\n",
    "logReg_Bal_L1 = LogisticRegression(fit_intercept = True, class_weight= 'balanced', \n",
    "                                   penalty = 'l1', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "\n",
    "# running logistic regression on balanced dataset, while including L2 Regularization (Ridge)\n",
    "logReg_Bal_L2 = LogisticRegression(fit_intercept = True, class_weight= 'balanced', \n",
    "                                   penalty = 'l1', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "\n",
    "# running logistic regression on un-balanced dataset, while including L1 Regularization (Ridge)\n",
    "logReg_Unbal_L1 = LogisticRegression(fit_intercept = True, \n",
    "                                   penalty = 'l1', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "\n",
    "\n",
    "# running logistic regression on un-balanced dataset, while including L2 Regularization (Ridge)\n",
    "logReg_Unbal_L2 = LogisticRegression(fit_intercept = True, \n",
    "                                   penalty = 'l2', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "\n",
    "\n",
    "# running logistic regression using SMOTE with unbalanced dataset, while including L1 Regularization (Lasso)\n",
    "logReg_Smote_L1 = LogisticRegression(fit_intercept = True, \n",
    "                                   penalty = 'l1', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "\n",
    "\n",
    "# running logistic regression using SMOTE with unbalanced dataset, while including L2 Regularization (Ridge)\n",
    "logReg_Smote_L2 = LogisticRegression(fit_intercept = True, \n",
    "                                   penalty = 'l1', solver='liblinear')#.fit(Xtr, Ytr)\n",
    "                                                                                                                                                                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8146b2",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logReg_Smote_L2, Xtr, Ytr, cv = 4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8419fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logReg_models = [logReg_Bal_L1, logReg_Bal_L2, logReg_Unbal_L1, logReg_Unbal_L2,\n",
    "#                 logReg_Smote_L1, logReg_Smote_L2]\n",
    "\n",
    "# def CV(model, K):\n",
    "#     cv_list = []\n",
    "#     for k in range(K):\n",
    "#         cv_list.append(cross_val_score(logReg_Smote_L2, Xtr, Ytr, cv = 4).mean())\n",
    "    \n",
    "#     return cv_list\n",
    "\n",
    "\n",
    "# # for model in logRed_models:\n",
    "# #     log\n",
    "    \n",
    "# log1_cv = CV(logReg_Smote_L1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_Bal_L1 = logReg_Bal_L1.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b260905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte_hat = logReg_Bal_L1.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58916eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(Yte, Yte_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f88736",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c28f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da866d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_tr = metrics.plot_roc_curve(logReg_Smote_L2.fit(Xtr,Ytr), Xtr, Ytr)\n",
    "# roc_te = metrics.plot_roc_curve(logReg_Smote_L2.fit(Xtr,Ytr), Xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1bc89",
   "metadata": {},
   "source": [
    "## Model 2: SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1997f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "svmLinear = svm.SVC(kernel='linear', random_state=100)\n",
    "svmRBF = svm.SVC(kernel='rbf', random_state=100)\n",
    "svmPoly = svm.SVC(kernel='poly', random_state=100)\n",
    "logistic = LogisticRegression()\n",
    "dTree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7303865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(svmLinear, Xtr, Ytr, cv=5)\n",
    "# cross_val_score(svmRBF, Xtr, Ytr, cv=5)\n",
    "# cross_val_score(svmPoly, Xtr, v, cv=5)\n",
    "# cross_val_score(dTree, Xtr, Ytr, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b02b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9bfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b3946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c39d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0b993d",
   "metadata": {},
   "source": [
    "## Model 3: Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fee3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f81e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = rf_clf.predict_proba(Xte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916799bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get false and true positive rates\n",
    "fpr, tpr, thresholds = roc_curve(Yte, probas[:,0], pos_label=0)\n",
    "\n",
    "# get area under the curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# PLOT ROC curve\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')\n",
    "plt.title('ROC Curve for RF classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1b1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5e5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3d25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493b7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46be1c8",
   "metadata": {},
   "source": [
    "## Model 4: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69222135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d739f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f73683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17996a18",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50d379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74284102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad12d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4471dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7c644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362917cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
